{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1.2 NLP Assignment - Pipeline Exit Ticket Digital\n",
        "**Name Entity Recognition (NER)** - An NLP task that involves identifying and classifying named entities in text into predefined categories such as person names, locations, organizations, dates, and more.\n",
        "\n",
        
        "The pipline function's task argument for name entity recognition is **“ner”**.\n",
        "\n",
        "For the model, use **“dslim/bert-base-NER”**\n",
        "\n",
        "**Instructions: Fix the code below:**"
      ],
      "metadata": {
        "id": "GNHj6pldu8Ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''NOTHING IN THIS BLOCK IS WRONG'''\n",
        "\n",
        "# Run this to download necessary libraries\n",
        "!pip install transformers[sentencepiece] # HG Transformer’s Library\n"
      ],
      "metadata": {
        "id": "Acc_xBwNwfnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdKP54Rmul0W"
      },
      "outputs": [],
      "source": [
        "from transformers\n",
        "\n",
        "# Initialize NER pipeline\n",
        "ner_pipeline = (\"NER\", "dslim/bert-base-NER\")\n",
        "\n",
        "# Input text\n",
        "text = \"Stop playing Brawl Stars during class!\"\n",
        "\n",
        "# Analyze named entities\n",
        "entities = pipeline(text)\n",
        "\n",
        "print(entities)\n",
        "\n",
        "# Nothing needs to be fixed under this comment\n",
        "output = \"\"\n",
        "for i in range(len(entities)):\n",
        "    token = entities[i]\n",
        "    output +=token[\"word\"].replace(\"#\",\"\")\n",
        "    if((i ==(len(entities)-1)) or token[\"end\"]!=entities[i+1][\"start\"]):\n",
        "        output +=\" \"\n",
        "print(output)"
      ]
    }
  ]
}
